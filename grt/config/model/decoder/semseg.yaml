semseg:
  _target_: nrdk.models.TransformerTensorDecoder
  decoder_layer:
    _target_: torch.nn.TransformerDecoderLayer
    d_model: ${size.d_model}
    nhead: ${size.nhead}
    dim_feedforward: ${size.d_feedforward}
    dropout: 0.1
    activation: gelu
    layer_norm_eps: 1e-5
    batch_first: true
    norm_first: true
    bias: true
  d_model: ${size.d_model}
  num_layers: 4
  shape: [1, 160, 160, 1]
  scale: [16.0, 16.0, 10.666, 16.0]
  w_min: 0.2
  patch: [1, 5, 5, 1]
  out_dim: 8
